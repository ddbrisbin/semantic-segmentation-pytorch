{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoadSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVYJrpWdER_e",
        "colab_type": "text"
      },
      "source": [
        "# Road Segmentation using CSAIL Vision Semantic Segmentation on KITTI\n",
        "\n",
        "This notebook trains several different models on the KITTI Road Segmentation dataset and evaluates the comparison. I uses the semantic-segmentation-pytorch project out of CSAIL Vision to perform the training and evaluation.\n",
        "\n",
        "Please note that due to github storage limits, the pretrained weights for HRNet encoder and ResNet101 Decoder are not included in the repo. These must be separetely downloaded from:\n",
        "\n",
        "https://drive.google.com/drive/folders/12ZbphYa_qXLANTsLTnogdUPSywpRrdsH?usp=sharing\n",
        "\n",
        "with a UM account and placed in the ckpt folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeNAG_vo4POn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "%cd /content\n",
        "\n",
        "git_repo_url = 'https://github.com/ddbrisbin/semantic-segmentation-pytorch.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  !git clone -q $git_repo_url\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWYvdCA9msgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Install Dependencies #####\n",
        "!pip3 install yacs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vrhUoWNlycy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##### Train models. #####\n",
        "%cd /content/semantic-segmentation-pytorch \n",
        "\n",
        "\n",
        "# uncomment the line corresponding to the config file you wish to run. \n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_hrnetv2.yaml\n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_mobilenetv2dilated-c1_deepsup.yaml\n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet101-upernet.yaml\n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resne50dilated-ppm_deepsup.yaml\n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet18dilated-ppm_deepsup.yaml\n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet50-upernet.yaml\n",
        "# !python3 train.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet50dilated-ppm_deepsup.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro9HPBGZ1SSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Evaluate trained models on holdout data. #####\n",
        "%cd /content/semantic-segmentation-pytorch \n",
        "\n",
        "#if using pretrained weights, please copy the corresponding folder in the trained_models folder to the ckpt folder.\n",
        "#Uncomment the desired evaluation \n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_hrnetv2.yaml\n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_mobilenetv2dilated-c1_deepsup.yaml\n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet101-upernet.yaml\n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet101dilated-ppm_deepsup.yaml\n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet18dilated-ppm_deepsup.yaml\n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet50-upernet.yaml\n",
        "# !python3 eval_multipro.py --gpus 0 --cfg /content/semantic-segmentation-pytorch/config/kitti_resnet50dilated-ppm_deepsup.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFOgOX_KImSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Download trained models and exemplar images. #####\n",
        "from google.colab import files\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet101-upernet/decoder_epoch_40.pth')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet101-upernet/encoder_epoch_40.pth')\n",
        "# files.download(\"/content/semantic-segmentation-pytorch/ckpt/kitti_mnv2d_c1deepsup/result/uu_000009.png\")\n",
        "# files.download(\"/content/semantic-segmentation-pytorch/ckpt/kitti_mnv2d_c1deepsup/result/um_000005.png\")\n",
        "\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-hrnetv2-c1/decoder_epoch_40.pth')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-hrnetv2-c1/encoder_epoch_40.pth')\n",
        "# files.download(\"/content/semantic-segmentation-pytorch/ckpt/kitti-hrnetv2-c1/result/uu_000009.png\")\n",
        "# files.download(\"/content/semantic-segmentation-pytorch/ckpt/kitti-hrnetv2-c1/result/um_000005.png\")\n",
        "\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet101-upernet/decoder_epoch_40.pth')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet101-upernet/encoder_epoch_40.pth')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet101-upernet/result/uu_000009.png')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet101-upernet/result/um_000005.png')\n",
        "\n",
        "\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet50dilated-ppm_deepsup/decoder_epoch_25.pth')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet50dilated-ppm_deepsup/encoder_epoch_25.pth')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet50dilated-ppm_deepsup/result/uu_000009.png')\n",
        "# files.download('/content/semantic-segmentation-pytorch/ckpt/kitti-resnet50dilated-ppm_deepsup/result/um_000005.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}